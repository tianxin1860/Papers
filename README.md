 # Papers

 ### representation learning

| Paper | 核心思想 | 备注 |
| --- | --- |--- |
|[Learned in Translation: Contextualized Word Vectors](https://einstein.ai/static/images/pages/research/cove/McCann2017LearnedIT.pdf)  | 基于双向LSTM pretrain 翻译模型作为 encoder | 2017-NIPS|
|[Multi-Task Deep Neural Networks for Natural Language Understanding](https://arxiv.org/pdf/1901.11504.pdf)  |  利用 multi-task finetune 提升 reprsentation 的领域泛化性 |2019-arXiv|
